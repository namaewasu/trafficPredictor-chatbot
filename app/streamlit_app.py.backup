import streamlit as st
import sys
import os
import pandas as pd
import json
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go

# Models dizinini path'e ekle
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'models'))

from chatbot_gpt import GPTTrafficChatbot
from chatbot_gemini import GeminiTrafficChatbot
from model_comparison import ModelComparison

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="ğŸš— AkÄ±llÄ± Trafik AsistanÄ±", 
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #667eea;
    }
    
    .user-message {
        background-color: #f0f2f6;
        border-left-color: #667eea;
    }
    
    .bot-message {
        background-color: #e8f4fd;
        border-left-color: #1f77b4;
    }
    
    .metric-card {
        background: linear-gradient(45deg, #667eea, #764ba2);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem;
    }
    
    .sidebar-info {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #dee2e6;
    }
</style>
""", unsafe_allow_html=True)

def initialize_session_state():
    """Session state deÄŸiÅŸkenlerini baÅŸlat"""
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    if 'gpt_bot' not in st.session_state:
        st.session_state.gpt_bot = None
    
    if 'gemini_bot' not in st.session_state:
        st.session_state.gemini_bot = None
    
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = 'GPT'
    
    if 'models_loaded' not in st.session_state:
        st.session_state.models_loaded = False

def load_models():
    """Modelleri yÃ¼kle"""
    if st.session_state.models_loaded:
        return True
    
    try:
        # Data path
        data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'traffic_chatbot_dataset.csv')
        
        # GPT Model
        st.session_state.gpt_bot = GPTTrafficChatbot()
        gpt_success = st.session_state.gpt_bot.load_data(data_path)
        
        if gpt_success:
            st.session_state.gpt_bot.train_intent_classifier()
        
        # Gemini Model
        st.session_state.gemini_bot = GeminiTrafficChatbot()
        gemini_success = st.session_state.gemini_bot.load_data(data_path)
        
        if gemini_success:
            st.session_state.gemini_bot.train_intent_classifier()
        
        st.session_state.models_loaded = True
        return True
        
    except Exception as e:
        st.error(f"Model yÃ¼kleme hatasÄ±: {e}")
        return False

def display_chat_message(message, is_user=True):
    """Chat mesajÄ±nÄ± gÃ¶ster"""
    if is_user:
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ğŸ‘¤ Sen:</strong> {message}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message bot-message">
            <strong>ğŸ¤– Asistan:</strong> {message}
        </div>
        """, unsafe_allow_html=True)

def main():
    """Ana uygulama"""
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸš— AkÄ±llÄ± Trafik AsistanÄ±</h1>
        <p>Ä°stanbul trafik durumu ve yol tarifleri iÃ§in AI destekli chatbot</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Session state baÅŸlatma
    initialize_session_state()
    
    # Sidebar
    with st.sidebar:
        st.markdown("## âš™ï¸ Ayarlar")
        
        # Model seÃ§imi
        selected_model = st.selectbox(
            "ğŸ¤– Model SeÃ§in",
            ["GPT", "Gemini"],
            index=0 if st.session_state.selected_model == 'GPT' else 1
        )
        st.session_state.selected_model = selected_model
        
        # API Key giriÅŸi (isteÄŸe baÄŸlÄ±)
        st.markdown("### ğŸ”‘ API AnahtarlarÄ± (Opsiyonel)")
        st.markdown("""
        <div class="sidebar-info">
        <small>API anahtarlarÄ± girerseniz daha geliÅŸmiÅŸ yanÄ±tlar alabilirsiniz. 
        Girmezseniz temel template yanÄ±tlar verilir.</small>
        </div>
        """, unsafe_allow_html=True)
        
        gpt_api_key = st.text_input(
            "OpenAI API Key", 
            type="password",
            help="OpenAI API anahtarÄ±nÄ±zÄ± girin"
        )
        
        gemini_api_key = st.text_input(
            "Google Gemini API Key", 
            type="password",
            help="Google Gemini API anahtarÄ±nÄ±zÄ± girin"
        )
        
        # Model yÃ¼kleme
        if st.button("ğŸ”„ Modelleri YÃ¼kle", type="primary"):
            with st.spinner("Modeller yÃ¼kleniyor..."):
                if load_models():
                    # API anahtarlarÄ±nÄ± ayarla
                    if gpt_api_key and st.session_state.gpt_bot:
                        st.session_state.gpt_bot.api_key = gpt_api_key
                    
                    if gemini_api_key and st.session_state.gemini_bot:
                        st.session_state.gemini_bot.api_key = gemini_api_key
                    
                    st.success("âœ… Modeller baÅŸarÄ±yla yÃ¼klendi!")
                else:
                    st.error("âŒ Model yÃ¼kleme baÅŸarÄ±sÄ±z!")
        
        # Model durumu
        st.markdown("### ğŸ“Š Model Durumu")
        if st.session_state.models_loaded:
            st.success("âœ… Modeller hazÄ±r")
            if st.session_state.gpt_bot and hasattr(st.session_state.gpt_bot, 'accuracy'):
                st.metric("GPT Accuracy", f"{st.session_state.gpt_bot.accuracy:.3f}")
            if st.session_state.gemini_bot and hasattr(st.session_state.gemini_bot, 'accuracy'):
                st.metric("Gemini Accuracy", f"{st.session_state.gemini_bot.accuracy:.3f}")
        else:
            st.warning("âš ï¸ Modeller henÃ¼z yÃ¼klenmedi")
        
        # Chat geÃ§miÅŸini temizle
        if st.button("ğŸ—‘ï¸ Chat GeÃ§miÅŸini Temizle"):
            st.session_state.chat_history = []
            st.rerun()
        
        # Ã–rnek sorular
        st.markdown("### ğŸ’¡ Ã–rnek Sorular")
        example_questions = [
            "Merhaba",
            "YarÄ±n sabah trafik nasÄ±l?",
            "BeÅŸiktaÅŸ'tan KadÄ±kÃ¶y'e nasÄ±l giderim?",
            "Alternatif yol var mÄ±?",
            "E5 Ã¼zerinde ÅŸu an durum nasÄ±l?",
            "Ne zaman Ã§Ä±kmalÄ±yÄ±m?",
            "Park yeri var mÄ±?",
            "YaÄŸmurda trafik nasÄ±l etkilenir?"
        ]
        
        for question in example_questions:
            if st.button(question, key=f"example_{question}"):
                if st.session_state.models_loaded:
                    # SeÃ§ilen modeli kullan
                    if st.session_state.selected_model == 'GPT' and st.session_state.gpt_bot:
                        response = st.session_state.gpt_bot.chat(question)
                    elif st.session_state.selected_model == 'Gemini' and st.session_state.gemini_bot:
                        response = st.session_state.gemini_bot.chat(question)
                    else:
                        response = {'response': 'Model hazÄ±r deÄŸil. LÃ¼tfen modelleri yÃ¼kleyin.'}
                    
                    # Chat geÃ§miÅŸine ekle
                    st.session_state.chat_history.append({
                        'user': question,
                        'bot': response['response'],
                        'timestamp': datetime.now().isoformat(),
                        'model': st.session_state.selected_model,
                        'intent': response.get('intent', 'unknown'),
                        'confidence': response.get('confidence', 0)
                    })
                    st.rerun()
                else:
                    st.warning("Ã–nce modelleri yÃ¼kleyin!")
                    
    # Ana alan - Sol ve saÄŸ kolon
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("## ğŸ’¬ Chat")
        
        # Chat input
        user_input = st.chat_input("Trafik hakkÄ±nda bir ÅŸey sorun...", key="chat_input")
        
        if user_input and st.session_state.models_loaded:
            # SeÃ§ilen modeli kullan
            if st.session_state.selected_model == 'GPT' and st.session_state.gpt_bot:
                with st.spinner("GPT yanÄ±t hazÄ±rlÄ±yor..."):
                    response = st.session_state.gpt_bot.chat(user_input)
            elif st.session_state.selected_model == 'Gemini' and st.session_state.gemini_bot:
                with st.spinner("Gemini yanÄ±t hazÄ±rlÄ±yor..."):
                    response = st.session_state.gemini_bot.chat(user_input)
            else:
                response = {'response': 'Model hazÄ±r deÄŸil. LÃ¼tfen modelleri yÃ¼kleyin.'}
            
            # Chat geÃ§miÅŸine ekle
            st.session_state.chat_history.append({
                'user': user_input,
                'bot': response['response'],
                'timestamp': datetime.now().isoformat(),
                'model': st.session_state.selected_model,
                'intent': response.get('intent', 'unknown'),
                'confidence': response.get('confidence', 0)
            })
            
            st.rerun()
        
        elif user_input and not st.session_state.models_loaded:
            st.warning("âš ï¸ Ã–nce modelleri yÃ¼kleyin!")
        
        # Chat geÃ§miÅŸini gÃ¶ster
        if st.session_state.chat_history:
            st.markdown("### ğŸ“ Sohbet GeÃ§miÅŸi")
            
            for i, chat in enumerate(reversed(st.session_state.chat_history[-10:])):  # Son 10 mesaj
                with st.container():
                    display_chat_message(chat['user'], is_user=True)
                    display_chat_message(chat['bot'], is_user=False)
                    
                    # Detay bilgiler
                    with st.expander(f"ğŸ“Š Detaylar - {chat.get('model', 'Unknown')} Model"):
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("Intent", chat.get('intent', 'N/A'))
                        with col_b:
                            st.metric("Confidence", f"{chat.get('confidence', 0):.2f}")
                        with col_c:
                            st.metric("Model", chat.get('model', 'N/A'))
                    
                    st.markdown("---")
        
        else:
            st.info("ğŸ’¬ HenÃ¼z bir sohbet baÅŸlamadÄ±. YukarÄ±daki input alanÄ±nÄ± kullanarak soru sorabilirsiniz!")
    
    with col2:
        st.markdown("## ğŸ“Š Ä°statistikler")
        
        if st.session_state.chat_history:
            # Intent daÄŸÄ±lÄ±mÄ±
            intents = [chat.get('intent', 'unknown') for chat in st.session_state.chat_history]
            intent_counts = pd.Series(intents).value_counts()
            
            fig = px.pie(
                values=intent_counts.values, 
                names=intent_counts.index,
                title="Intent DaÄŸÄ±lÄ±mÄ±"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Model kullanÄ±mÄ±
            models = [chat.get('model', 'unknown') for chat in st.session_state.chat_history]
            model_counts = pd.Series(models).value_counts()
            
            fig2 = px.bar(
                x=model_counts.index,
                y=model_counts.values,
                title="Model KullanÄ±mÄ±"
            )
            st.plotly_chart(fig2, use_container_width=True)
            
            # Confidence skorlarÄ±
            confidences = [chat.get('confidence', 0) for chat in st.session_state.chat_history]
            
            fig3 = px.histogram(
                confidences,
                title="Confidence Score DaÄŸÄ±lÄ±mÄ±",
                nbins=10
            )
            st.plotly_chart(fig3, use_container_width=True)
            
        else:
            st.info("ğŸ“Š Sohbet baÅŸladÄ±ÄŸÄ±nda istatistikler burada gÃ¶rÃ¼necek")
        
        # Model karÅŸÄ±laÅŸtÄ±rma bÃ¶lÃ¼mÃ¼
        st.markdown("## âš–ï¸ Model KarÅŸÄ±laÅŸtÄ±rmasÄ±")
        
        if st.button("ğŸš€ Model Performans Testi Ã‡alÄ±ÅŸtÄ±r", type="secondary"):
            if st.session_state.models_loaded:
                with st.spinner("Model karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±lÄ±yor..."):
                    try:
                        comparison = ModelComparison()
                        comparison.gpt_bot = st.session_state.gpt_bot
                        comparison.gemini_bot = st.session_state.gemini_bot
                        
                        # Test verilerini hazÄ±rla
                        test_results = comparison.run_performance_test()
                        report, metrics = comparison.create_comparison_report()
                        
                        # SonuÃ§larÄ± gÃ¶ster
                        st.success("âœ… Test tamamlandÄ±!")
                        
                        # Metrikler
                        col_x, col_y = st.columns(2)
                        with col_x:
                            st.metric("GPT Accuracy", f"{metrics['model_accuracy']['GPT']:.3f}")
                            st.metric("GPT Avg Time", f"{metrics['response_time']['GPT_avg']:.3f}s")
                        
                        with col_y:
                            st.metric("Gemini Accuracy", f"{metrics['model_accuracy']['Gemini']:.3f}")
                            st.metric("Gemini Avg Time", f"{metrics['response_time']['Gemini_avg']:.3f}s")
                        
                        # Kazanan
                        winner = "GPT" if metrics['model_accuracy']['GPT'] > metrics['model_accuracy']['Gemini'] else "Gemini"
                        st.success(f"ğŸ† Accuracy KazananÄ±: {winner}")
                        
                    except Exception as e:
                        st.error(f"Test hatasÄ±: {e}")
            else:
                st.warning("Ã–nce modelleri yÃ¼kleyin!")

if __name__ == "__main__":
    main() 